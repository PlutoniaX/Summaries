

 The text provides brief biographical information about Henry A. Kissinger, Eric Schmidt, and Daniel Huttenlocher. 

 Kissinger served as the 56th US Secretary of State, received multiple awards, and is currently the chairman of Kissinger Associates. 

 Schmidt is a technologist, entrepreneur, and philanthropist who helped grow Google and cofounded Schmidt Futures and Reimagine with Eric Schmidt podcast. 

 Huttenlocher is the inaugural dean of the MIT Schwarzman College of Computing, previously served as founding dean and vice provost of Cornell Tech, and has a mix of academic and industry experience. 

 Huttenlocher also serves as chair of the board of the John D. and Catherine T. MacArthur Foundation, and as a member of the boards of Amazon and Corning.

The text is the copyright information and table of contents for the book "The Age of AI: And Our Human Future" authored by Henry A. Kissinger, Eric Schmidt, and Daniel Huttenlocher. The book discusses the impact of artificial intelligence on global politics, economics, and society, and is divided into chapters that explore the current state of affairs, the history of AI, and global network platforms. The book is published by John Murray Publishers.

The text is the preface of the book "The Age of AI: And Our Human Future" authored by Henry A. Kissinger, Eric Schmidt, and Daniel Huttenlocher. The preface describes how the book came about through discussions about the impact of artificial intelligence (AI) on various fields of human endeavor. It highlights the increasing popularity of AI and the significant funding raised by AI start-ups in the United States, Asia, and Europe. The authors emphasize that AI is not an industry, but an enabler of many industries and facets of human life.

The book discusses the disruptive and transformative nature of artificial intelligence (AI) on human identity and reality. It raises questions on various AI-enabled innovations, including their impact on health, biology, space, quantum physics, and war, as well as their perception of reality beyond humans. The authors, who have been meeting for four years, aim to provide readers with tools to answer these questions. Despite their varying degrees of optimism about AI, they agree on its significant impact on human history, and the book neither celebrates nor bemoans AI but acknowledges its ubiquity.

The book acknowledges the impact of AI on human understanding and seeks to provide a template for readers to decide what the future should be. Chapter 1 describes the significant achievement of AlphaZero, an AI program developed by Google DeepMind, which defeated Stockfish, the most powerful chess program in the world, with its entirely AI-trained style. Prior programs relied on human experience and knowledge, whereas AlphaZero had no pre-programmed moves or strategies derived from human play. The victory of AlphaZero highlights the significant potential of AI beyond human reasoning and strategy.

AlphaZero is a chess program that trained for four hours by playing against itself and emerged as the most effective chess program in the world. It deployed unorthodox tactics and sacrificed vital pieces because it predicted they would maximize its probability of winning. AlphaZero did not have a human-like strategy, but instead had its own logic informed by its ability to recognize patterns of moves across vast sets of possibilities. Researchers at MIT discovered a novel antibiotic that was able to kill strains of bacteria that had been resistant to all known antibiotics, which typically takes years of expensive and painstaking work.

Researchers at MIT invited AI to participate in the process of discovering a novel antibiotic by developing a training set of known molecules and encoding data about each. The AI learned the attributes of molecules predicted to be antibacterial and identified attributes that had eluded human conception or categorization. The AI was instructed to survey a library of 61,000 molecules for molecules that would be effective as antibiotics, did not look like any existing antibiotics, and would be nontoxic. One molecule, named halicin, fit the criteria and was identified as an antibiotic for which there was no known antibiotic. The AI made the identification process more efficient and inexpensive.

An AI was able to identify new relationships and qualities of molecules that humans had not perceived, and discovered a new antibiotic that humans could not articulate precisely why it worked. OpenAI also demonstrated GPT3, an AI model that can generate human-like text in response to prompts, questions, and topics.

Models like GPT3 generate possible responses to various inputs by consuming information online and are difficult to evaluate as they do not solve specific problems. GPT3, a language model, can understand information but does not have a conscience, sense of morality or independent thought as it has not been trained for these traits.

The development of AI, particularly machine learning methods using deep neural networks, has led to machines performing tasks that require human-level intelligence. These machines are able to acquire knowledge and capability in significantly briefer time frames than human learning processes require. Developers create programs, assign objectives, and permit them to train for a brief period. The machines are able to master their subject differently from humans and achieve results that are beyond the capacity of human minds to calculate. AI is rapidly expanding into applications in medicine, transportation, law enforcement, defense, and other fields. This technology has the potential to revolutionize human affairs.

AI, powered by new algorithms and increasingly plentiful and inexpensive computing power, is becoming ubiquitous and has the potential to access different aspects of reality from the ones humans access. Its advent is historically and philosophically significant and attempts to halt its development will merely cede the future to those courageous enough to face its implications. AI achieves human or superhuman levels of performance in some tasks but makes errors or produces nonsensical results in others. AI's mysteries should prompt us to ask questions about its impact on human perception, cognition, interaction, culture, and our concept of humanity.

The history of human exploration and knowledge acquisition has been based on the conviction that applying human reason to problems can yield measurable results, transforming our world and fostering confidence in our ability to understand and confront challenges. However, the advent of AI raises the question of whether there is a form of logic that humans have not achieved or cannot achieve, exploring aspects of reality we may never directly know. As AI discovers new strategies and models that humans cannot comprehend, we must confront whether knowledge is advancing or receding from us.

While technology has changed throughout history, it has rarely fundamentally transformed the social and political structure of societies, with preexisting frameworks adapting to new technology. However, AI promises to transform all realms of human experience, ultimately occurring at the philosophical level and transforming how humans understand reality and our role within it. AI will be ubiquitous, augmenting human thought and action in both obvious and less consciously perceived ways. As more software incorporates AI, a web of software processes is unfolding across the world, driving and perceiving the pace and scope of events, overlaying aspects of our daily lives.

AI-powered technology operates in ways that may be beyond human understanding and will become a permanent companion in perceiving and processing information. It will alter our experience as reasoning beings and permanently change our relationship with reality. The rise of AI and its potential to match or surpass human intelligence marks the end of the postulated superiority of human reason and promises transformations more profound than those of the Enlightenment.

The advent of artificial general intelligence (AGI) will alter humanity's concept of reality and the way decisions are made. AI will transform machines into partners and lead to collaboration between humans and machines. This will bring about a world where seemingly impossible human goals are achieved and transform entire fields. The integration of AI in our lives will lead to difficult-to-define lines between purely human, purely AI, and hybrid human-AI decision making. In the political realm, big data-driven AI systems are informing the design and distribution of political messages to various demographics.

The use of AI in shaping the information space and military strategies can have profound and unpredictable effects on society, including altering power balances, requiring adaptation to traditional concepts of defense and deterrence, and creating divides between those who adopt the technology and those who do not. These changes may also lead to rivalries, technical incompatibilities, and mutual incomprehension between societies with different goals and moral limits regarding AI. Therefore, it is important for societies to understand these changes and reconcile them with their values, structures, and social contracts.

The development of AI, particularly through deep neural networks, has enabled machines to devise solutions beyond the scope of human imagination. When AI is applied in various fields, it will suggest new solutions that bear the stamp of nonhuman learning and evaluation. Failing to apply AI, at least as an adjunct to human efforts, may appear increasingly perverse or negligent once its performance outstrips humans for a given task. However, the use of AI in decision-making, especially in the context of national security, raises ethical and moral concerns that require careful consideration.

The emergence of a novel human-machine partnership is occurring where humans define a problem or goal for a machine, and the machine determines the optimal process to pursue in a realm just beyond human reach. This partnership has led to groundbreaking discoveries such as the AI-discovered antibiotic halicin, which expands treatment options. However, there are concerns about how to balance human oversight and reliance on AI recommendations.

The development of human-machine partnerships has led to groundbreaking discoveries, such as the AI-discovered antibiotic halicin and the first computer program to operate military aircraft and radar systems autonomously. However, the reliance on AI recommendations raises concerns about the balance between human oversight and machine control. Contemporary search engines guided by models informed by human behavior present challenges, as they may preemptively shape options without the user's knowledge. The advent of machines that can approximate human reason will alter both humans and machines, expanding our reality.

As AI becomes increasingly integrated into daily life, it has the potential to change humanity and its environment in unexpected ways. While AI can learn and make decisions, it lacks self-awareness, intention, motivation, morality, and emotion. As a result, it may develop unintended means of achieving objectives. Despite its opaque nature, an increasing number of individuals are learning to build, operate, and deploy AI. This could lead to a new epoch, but also presents risks if machines that consume human knowledge are used to diminish us.

The implications of AI for humanity's social, legal, philosophical, spiritual, and moral domains are poorly understood. AI has enabled new possibilities, such as predicting and mitigating natural disasters, but this has come at the cost of altering our relationship with reason and reality. Historically, societies have sought to understand and shape their environment through human reasoning, but AI introduces a powerful new player in this quest, for which existing philosophical concepts and societal institutions are unprepared.

The esteemed status of human reason has developed through successive historical epochs with interlocking explanations of reality and societal arrangements. Each epoch had their own concepts of the individual and society, and when prevailing understandings were no longer sufficient, revolutions in thought occurred. The emerging AI age challenges today's concept of reality. The central esteem of reason originated in ancient Greece and Rome, where the quest for knowledge was a defining aspect of both individual fulfillment and collective good. The Platonic quest supposed the existence of an objective, ideal reality toward which humanity has the capacity to journey. This conviction inspired Greek philosophers and their heirs to great achievements.

The pursuit of mathematics and understanding the inner harmonies of nature was elevated to an esoteric spiritual doctrine in the classical world. Thales of Miletus established a method of inquiry that inspired early modern scientific pioneers. The classical world perceived seemingly inexplicable phenomena that were ascribed to an array of gods. The eighteenth-century historian Edward Gibbon described a world in which pagan deities stood as explanations for fundamentally mysterious natural phenomena that were deemed important or threatening.

Greek and Roman cultures did not have a scientific explanation for seasonal changes and instead offered the Eleusinian Mysteries as an alternative, which enacted the story of the harvest goddess Demeter and her daughter Persephone. Monotheistic religions shifted the balance between reason and faith, with the early church holding that the hidden reality that the classical world had sought was the divine, accessible only through worship and mediated by a religious establishment.

During the Middle Ages, people sought to know God first and the world second, with the world only to be known through God. Scholasticism became the primary guide for the quest to comprehend reality, with the church remaining the arbiter of legitimacy. Theologians and scientists were chastised for daring to omit theology as an intermediary. Despite progress in describing and depicting the universe, little progress was made in explaining it, with every phenomenon ascribed to the work of the Lord. The Western world underwent twin revolutions in the fifteenth and sixteenth centuries that introduced a new way of thinking about the world.



The printing press enabled the spread of ideas directly to the masses in languages they understood, nullifying the need for the church to interpret concepts and beliefs. 

The Protestant Reformation declared individuals responsible for defining the divine for themselves, leading to the validation of individual faith and the probing of received authority in religion and other realms. 

The revolutionary era saw innovative technology, novel paradigms, and widespread political and social adaptations reinforcing each other, enabling the spread of new ideas faster than they could be restricted. 

Centralized authorities were no longer able to stop the proliferation of printing technology or effectively ban disfavored ideas, leading to diversity and fragmentation in many cases attended by violent conflict.



The Renaissance era was marked by scientific and intellectual progress, but also ongoing religious, dynastic, national, and class-driven disputes leading to disruption and peril. 

The era saw a revival of classical learning, resulting in art, architecture, and philosophy that celebrated human achievement and aimed to foster individuals capable of full participation in civic life through clear thought and expression. 

Humanism, the guiding principle of the era, cultivated a love for reading and learning, and inspired new inquiries into the underlying mechanisms of the natural world and the means by which they could be measured and cataloged. 

Scholars began to form systems of thought beyond the restoration of continental Christian unity, such as Niccol Machiavelli's argument that state interests were distinct from their relationship to Christian morality, leading to an exploration of historical knowledge and increasing sense of agency over the mechanisms of society.

The era of geographic exploration brought the Western world into contact with societies that had different gods, histories, and economic and social structures. This posed profound philosophical challenges for the Western mind, which had assumed its own centrality. The question arose whether diverging cultures and experiences of reality were independently valid or whether they were waiting for the Europeans to awaken them to new aspects of reality. Most Western explorers and thinkers concluded that the newly encountered societies had no fundamental knowledge worth adopting.

The era of geographic exploration broadened the Western mind and gave rise to concepts of universal humanity and human rights. The West amassed a repository of knowledge and experience from all corners of the world, which led to rapid progress in mathematics, astronomy, and natural sciences. Advances in technology and methodology, such as the scientific method, allowed scientists to make iterative progress, revealing new discoveries, patterns, and connections that could be applied to practical aspects of daily life. These breakthroughs led to the general sentiment that new layers of reality were being uncovered.

The Enlightenment period was a time when society needed a philosophy to guide their quest for understanding the world and their role in it. Philosophers declared reason as the power to interact with the environment and fulfill their purpose. The West returned to fundamental questions on reality and perception, unencumbered by tradition. Scholars and philosophers were willing to risk their cultural traditions and established conceptions of reality to investigate these questions.

During the Enlightenment period, philosophers like Bishop Berkeley, Leibniz, and Spinoza questioned traditional concepts of reality and faith. Berkeley argued that reality consisted of God and minds, while Leibniz posited that monads formed the essence of things. Spinoza sought to arrive at an ethical system through reason alone, and believed that the ultimate form of knowledge was the intellectual love of God. These explorations led to uncertainty about the relationship between reason, faith, and reality, which Immanuel Kant addressed in his Critique of Pure Reason.

In his Critique, Kant proposed that reason should be applied to understand its own limitations and that human cognition and experience filter and distort all that we know. Objective reality, in the strictest sense, is inherently beyond our direct knowledge, but we may maintain beliefs about it. For two hundred years, the human mind's limitations seemed unimportant as it was the only way to access reality, but now, with AI, an alternative mechanism for accessing reality is emerging.

After Kant, the quest to understand reality took the form of more precise observation and cataloging of knowledge. The Encyclopdie was a sweeping effort to compile and link the discoveries and deductions of great thinkers in numerous disciplines. In the political realm, reasoning minds serving various state interests were not apt to reach the same conclusions. The French Revolution, one of the most rational political movements of the age, produced social upheavals and political violence on a scale unseen in Europe for centuries. The Enlightenment separated reason from tradition.

The Enlightenment applied reason to define and solve problems, proposing perpetual peace through agreed-upon rules for independent states. However, armed reason and modern scientific advancements led to total war and societal-level destruction. Romanticism emerged as a reaction to Enlightenment's mechanistic certainties, valuing human feeling and imagination. Meanwhile, advanced theoretical physics challenged human perception, leading to disorienting consequences. The vision of a reasoned, negotiated international system has persisted but achieved only intermittent success.

Classical physics posited an absolute and consistent world, but as scientists sought clearer explanations, they encountered results that couldn't be explained. Albert Einstein's work on quantum physics and relativity solved many riddles but revealed a newly mysterious picture of physical reality, challenging long-standing assumptions about knowledge. Werner Heisenberg's uncertainty principle implied a completely accurate picture of reality may not be available at any time, and physical reality was created by observation. The question of whether reality had a single objective form and whether human minds could access it had preoccupied philosophers since Plato.

The article discusses the idea that observation affects and orders reality, and that scientific instruments are not completely neutral tools, as they have a physical interaction with the object of observation. This affects attempts to describe the phenomenon accurately. The human mind must choose which aspect of reality it wants to know accurately at a given moment. The article explores how AI may allow scientists to fill in gaps in human ability to measure and perceive phenomena, or process vast amounts of data. The article also discusses how 20th-century philosophy began to embrace the ambiguity and relativity of perception, and how knowledge can be found in generalizations about similarities across phenomena, rather than a single essence of things identifiable by reason.

The article discusses the limitations of defining and cataloging all things with sharply delineated boundaries, and instead proposes seeking to define similarities and achieve familiarity with concepts even if they have blurred edges. This idea informed theories of AI and machine learning, which can identify networks of similarities and make sense of reality by learning patterns and types. The article notes that human dependence on digital augmentation is creating a new epoch in which the Enlightenment premise of a knowable world being unearthed by human minds is being challenged.

The technological advances of the age of reason were seen as extensions of previous practices until the revolution of digitization and the advancement of AI produced truly new phenomena. Computers have become faster and smaller, embedded in various devices and systems, and communication across them is instantaneous. All levels of human organization have been affected by digitization, with individuals possessing more information than ever before, and corporations and governments utilizing digital, data-driven processes.

Collectors and aggregators of user data, including corporations and governments, wield significant power and influence in cyberspace. The digital revolution has made human thought less contextual and conceptual, with digital natives relying on search engines and delegating aspects of their thinking to technology. The internet inundates users with the opinions of others, depriving them of solitude required for sustained reflection and the development of convictions and wisdom necessary to explore new horizons. The digital world values approbation over introspection.

The digital world challenges the Enlightenment idea that reason is the most important element of consciousness by offering meaningful connections regardless of distance, time, and language. AI is increasingly applied to our lives and is altering the role of our minds in shaping and assessing our choices and actions. Alan Turing proposed measuring intelligence by external behavior, sidestepping centuries of philosophical debate on the nature of intelligence. His imitation game suggested that if a machine operated so proficiently that observers could not distinguish its behavior from a human, it could be considered intelligent.

The Turing test assesses intelligent machines' performance in humanlike activities rather than requiring total indistinguishability from humans. John McCarthy defined artificial intelligence as machines that can perform tasks characteristic of human intelligence, shifting the focus to performance rather than deeper philosophical, cognitive, or neuroscientific dimensions. Traditional programs could not adapt to imprecise inputs, but recent computing innovations have created AIs that can learn by consuming vast amounts of information and are imprecise, dynamic, emergent, and capable of equaling or exceeding human achievement in various fields.

AI with imprecise function can draw observations and conclusions based on data without exact inputs and outputs, and it evolves and identifies novel solutions. Machine-learning algorithms improve upon imprecise results and are making remarkable progress in fields like aviation, where AI is poised to have a significant impact on the future of both military and civilian aviation. The breakthrough of AlphaZero in the world of chess is an example of the revolutionary nature of these learning techniques.

This text discusses the evolution and current state of various types of machine learning, including their structure, capabilities, and limitations. The idea of creating a machine capable of performing tasks with human competence has been around for centuries, but early attempts to create practically useful AIs by encoding human expertise proved difficult. While AI has made great advances in fields that use precise characterization, such as chess and algebraic manipulation, inherent ambiguity has brought progress to a halt in other fields, like language translation and visual object recognition.

Early AI attempted to teach machines using symbolic representation, but this approach failed in dynamic tasks. This led to a decline in funding during the "AI winter." In the 1990s, a breakthrough occurred with a shift towards machine learning, allowing machines to learn on their own using neural networks and extracting patterns from large datasets. This approach has led to practical applications and progress in the field of AI.

Machine learning was born from a shift towards learning from observation rather than encoding human-distilled insights into machines. This approach has led to significant progress in fields such as visual object recognition and the prediction of antibacterial properties of molecules. Modern AI uses machine learning to create and adjust models based on real-world feedback and can identify partial relationships between properties and effects.

Machine learning algorithms measure the quality of outcomes to be learned rather than directly specified, and neural networks are driving most of the advances in AI. The structure of nodes and connections between them in neural networks encode information, and recent advances in computing power and algorithms have enabled the development of more sophisticated networks. The discovery of halicin, a potential antibiotic, was made through a neural network that captured the association between molecules and their potential to inhibit bacterial growth without information about chemical processes or drug functions.



Deep learning allows neural networks to capture complex relationships, including those that can elude humans, through the training phase where the AI adjusts its weights based on data. 

Neural network training is resource-intensive and divided into two steps: training and inference. 

The AI does not reason like humans, but rather applies the model it developed during the training phase to reach conclusions in the inference phase. 

The techniques used to create AI must vary based on the tasks it performs, posing a fundamental challenge in deploying machine learning.

Machine learning algorithms, neural networks, and learning techniques offer new possibilities such as cancer-spotting AI. There are three forms of machine learning: supervised, unsupervised, and reinforcement learning. Supervised learning involves training the model with a dataset containing example inputs and individually labeled outputs. Unsupervised learning can be used when developers only have troves of data and aims to extract potentially useful insights. Supervised learning has been effective in creating AIs that recognize images, while unsupervised learning is useful for situations where developers have only troves of data.

Unsupervised learning allows AIs to identify patterns or anomalies without having any information regarding outcomes, making it useful for marketers and fraud analysts. AIs trained through unsupervised learning can identify patterns that humans might miss because of their subtlety or the scale of the data. Reinforcement learning is a third major category of machine learning in which AI is an active agent in a controlled environment, observing and recording responses to its actions.

AI training in simulated environments requires feedback provided by reward functions. Automated reward functions are essential, as humans cannot keep up with the speed of AI training. Reinforcement learning requires human involvement in creating the AI training environment, specifying the simulator and reward function. Careful specification of the simulator and reward function is vital for meaningful results. AI has diverse applications in fields such as agriculture and medicine.

AI has diverse applications in detecting diseases, facilitating high-volume processes in finance, and revolutionizing translation capabilities. In the past, rules-based language translation programs failed due to the variability and subtlety of language. However, with the application of deep neural networks in 2015, machine translation leaped forward, and developers can continue to innovate in brilliant ways from the basic building blocks of machine learning.

To capture sequential dependencies in language translation, researchers developed networks that use already translated text as input alongside still-to-be-translated text. The most powerful of these networks are transformers, which do not require processing from left to right. In a shift from conventional supervised learning, researchers used parallel corpora, which does not require specific correspondence between inputs and outputs for training. This allowed AIs to be trained on informal writings and increased the amount and types of training data available.

The parallel corpora technique involves training AIs on untranslated texts in multiple languages, which increases the volume and types of data available for training. Google Translate's use of this technique resulted in a 60% improvement in performance. This advancement in language translation has the potential to transform various fields. Generative neural networks can create novel text or images, departing from their solution-identifying predecessors. The applications of these generators are vast.

Generative AI can create content with minimal input from authors, but can also create false depictions. Generative adversarial networks (GANs) train generator and discriminator networks to produce realistic outputs. GAN-trained AIs can suggest sentence completions, complete partial queries, and fill in details of outlined code. GPT3 is a notable example of generative AI that can produce human-like text. However, training GANs can be challenging and may produce poor results without proper checks.

Transformers like GPT3 can generate text, images, and code by detecting patterns in sequential elements. Trained on vast amounts of data, transformers have the potential to alter many fields and are subject to ongoing research. Machine learning has revolutionized AI and allowed it to exceed human performance in some areas, expanding its applicability and potential. These advances promise to allow AI to handle new tasks and generate new possibilities.



 AI enables personalized online searching by tailoring search engine results to individual users. 

 AI remembers previous queries and responses to produce increasingly specific and helpful concepts for users. 

 Online streaming services also use AI to make suggestions more focused and positive. 

 AI can steer users away from inappropriate content and towards content appropriate for their ages or preferences. 

 The outcome of AI getting to know people is largely positive as users become more likely to access content of interest. 

 The proposition of AI filtration is familiar and practical, akin to tourists hiring guides in foreign countries.



 Filtration in cyberspace can lead to personal echo chambers and discordance between different perspectives. 

 Personalization of news, books, and other sources of information can omit certain subjects and sources completely. 

 Managing the risks of AI is essential and cannot be left to any single group. 

 Contemporary machine-learning AI models reality on their own, without explaining or characterizing what they learn.

Humans must verify that AI is producing desired results as AI cannot reflect upon what it discovers or feel moral/philosophical compulsion. AI may produce unexpected discoveries, leaving it to humans to determine their significance and integrate them into existing knowledge. AI cannot contextualize or reflect like a human, so humans must regulate and monitor the technology.

AI can make mistakes, including rudimentary ones that any human would recognize. Dataset bias is a critical problem that can lead to misidentifications, especially for underrepresented groups. Training AIs on large quantities of similar images can lead to incorrect outcomes, and AI bias can result from human bias in training data or reward functions. Such challenges must be attended to as AI deployment often precedes troubleshooting.

The problem of bias in technology affects both AI and non-AI technologies, and it requires a serious response. AI can also misidentify objects due to its rigidity and lack of common sense. The brittleness of AI is due to its shallow learning and lack of self-awareness.

AI's inability to identify and avoid blunders underscores the need for testing to assess its capacities and predict when it is likely to fail. Professional certification, compliance monitoring, and oversight programs for AI are crucial societal projects. Testing processes should be developed to demonstrate an AI's reliability before its employment. The level of pre-use testing for AI deployments will likely depend on inherent riskiness, regulatory oversight, and market forces.

The division between learning and inference phases in machine learning allows for comprehensive testing and certification of AI behavior. AIs' learned models are static after training, making it possible for humans to assess their behavior without fear of unexpected or undesirable behavior. Auditing datasets and ensuring diverse training can further reduce the risk of AI faltering in operational contexts. AI behavior is constrained by its code, which sets the parameters of its possible actions and establishes limits on its behavior.

AI is constrained by its code, objective function, and ability to process inputs it's designed to recognize. AIs cannot break rules or take actions beyond their vocabulary. Their objective function defines and assigns what to optimize, limiting their potential actions. AIs can only process inputs they're programmed to recognize. Advances in machine learning have enabled rapid progress in AI, concentrated in the US and China, but many aspects still need development. AIs may one day write their own code but would still be limited by their objective function and lack self-reflection.

Developing more advanced AI requires substantial training data and computing infrastructure, but devising methods that use less data and power is a critical frontier. Complex tasks such as driving in chaotic settings remain challenging for AI, but it may be safer than human drivers for long-distance travel on highways. Predicting the rate of AI's advance is difficult, as progress is less predictable than Moore's Law. Language-translation AI advanced rapidly in just a few years, but it cannot be predicted when AI will achieve the qualities of a gifted professional translator.

AI is expected to become more compact, effective, and inexpensive, and will increasingly become a part of our daily lives. Progress in AI could yield neural networks equal in scale to the human brain in 15-20 years, allowing for the creation of AI savants capable of exceeding human performance in specific areas. Some developers are pushing for artificial general intelligence (AGI), capable of completing any intellectual task humans can do, but its development and definition remain uncertain.

The development of AGI relies heavily on machine learning, which may have limitations in its expertise. One potential approach is to combine traditional AIs trained in multiple fields to create a more well-rounded AGI. However, there is disagreement on whether true AGI is possible and what its characteristics would be. Developing such AIs would require massive computation power and be extremely expensive. Regardless, whether AI or AGI, human developers will continue to play an important role in creation and operation, as the algorithms, training data, and objectives reflect their values, motivations, and goals. As development costs decrease, automated systems will become more prevalent and potent.

AI devices will become increasingly prevalent in vehicles, tools, appliances, and applications, revolutionizing consumer experiences and enterprises. AI will save lives by reducing accidents, identifying diseases earlier and discovering drugs. It will improve transportation, reduce energy use, and moderate humans' environmental impact. AI will have startling effects on peace and war. However, the social repercussions of AI are difficult to predict, such as the challenges that may arise with automated language translation.

Instantaneous translation can lead to unintended offense and cultural misunderstandings. Advanced AI technology requires vast resources, driving concentration and advancement in organizations with access to such resources. Fictional visions of AI often involve machines with self-awareness, but the anxieties underlying these fantasies may miss the real risks and benefits of AI. It is important to pay attention to the potential risks and benefits of AI and ensure it is not created in isolation.

AI is already integrated into our daily lives, powering social media, web searches, streaming video, navigation, ride sharing, and countless other online services. This integration is happening rapidly and with little visibility, facilitated by network platforms that aggregate users at a global scale. The value of network platforms grows as more users adopt them, leading to a small number of providers dominating the market. These new types of relationships between AI, people, and governments have substantial implications for individuals, institutions, and nations.

Large network platforms with millions or billions of users increasingly rely on AI, creating an intersection between humans and AI on a scale of civilizational significance. Without oversight and discussion compatible with societal values, a rebellion may arise. Governments, network platform operators, and users must consider their goals and interactions to avoid disruption. Popular network platforms have user bases larger than most nations, with diffuse borders and interests that may differ from those of a nation. Despite being commercial entities, some network platforms may host economic and social interactions surpassing most countries without forming policies like a government would.

Network platforms are becoming significant geopolitical actors due to their scale, function, and influence. Platforms from the US and China seek to build user bases and commercial partnerships in strategically significant regions, introducing novel factors into foreign policy calculations. Platforms have become integral to individual life, political discourse, commerce, and government functions in some countries. Community standards set by network platform operators, often with the assistance of AI, provide an example of the incongruity between digital space and traditional rules and expectations, and can become as influential as national laws.

The rapid expansion of digital platforms and AI has led to challenges in regulating disinformation and content standards. Once AI is trained, it acts faster than human cognition, requiring attention to changes in thought, culture, politics, and commerce beyond the scope of a single human mind. When the digital world began to expand, there was no expectation of a philosophical framework or definition of the industry's relationship to national or global interests. Society assessed digital products and services based on practical and efficient solutions, with little demand for predictions about their broader societal impact.

AI-enabled network platforms lack a basic vocabulary and concepts for informed debate. Different entities have varying views on their operation and regulation. The nature and scale of network platforms bring different perspectives and priorities, creating tension and perplexity. A common frame of reference is necessary to understand their implications for individuals, companies, societies, nations, governments, and regions. Network platforms become more useful with more users, and AI is increasingly important for delivering their services at scale.

Social media platforms such as Facebook have developed community standards for the removal of objectionable content, but the sheer scale of monitoring makes it impossible for human moderators alone. AI is increasingly used for content moderation, relying on machine learning, natural language processing, and computer vision techniques. Facebook's human operators and users rely on AI to determine which content warrants consumption or review. Google's search engine also relies on AI for organizing and ranking information, with human developers adjusting algorithms.

Google's search engine has moved from human-developed algorithms to implementing machine learning, vastly improving the quality and usability of the search engine. As AI becomes increasingly critical to network platforms' functioning, it becomes a sorter and shaper of reality, affecting social, economic, political, and geopolitical influence. Positive network effects, where value rises with the number of participants, allow network platforms to have a broader, often transnational geographic scope with correspondingly few major competing services.

Positive network effects can increase the value and usefulness of a product or service, but can also lead to scarcity, delays, or loss of exclusivity. Positive network effects have been observed in markets such as stock exchanges and telephone networks, where more participants lead to more accurate valuations and higher value for each user. In some cases, positive network effects can create barriers to competition for other providers offering the same service.

Technological advances allowed telephone service providers to connect with each other, enabling subscribers to reach anyone regardless of their provider and reducing the positive network effect. Positive network effects can expand beyond national borders, with a small number of global network platforms dominating various services. The digital world has transformed daily life, with individuals relying on software processes to organize and consume vast amounts of data, contributing to the operation of nonhuman intelligence at a global scale.

AI-enabled network platforms use automated curation to guide, interpret, and record options for individuals based on a combination of their previous choices and popular selections. They aggregate information and experiences on a much broader scale than a single human mind can accommodate, providing answers and recommendations that can seem uncannily apt. As individuals interact with the AI and the AI adapts to their preferences, a tacit partnership forms, and individuals come to rely on the platform to perform functions traditionally distributed to businesses, governments, and other entities.

AI-enabled network platforms have become a combination of postal service, department store, concierge, confessor, and friend, creating a novel combination of intimate bond and remote connection. Users turn to AI as a guide or facilitator of a personalized experience, with the AI learning from and interacting with users. However, the logic of AI is nonhuman and often inscrutable to humans, with AI judged by the utility of its results rather than the process used to reach them. This signals a shift in priorities from earlier eras, where each step in a mental or mechanical process could be paused, inspected, and repeated by humans.

The use of smartphone map applications has replaced the traditional methods of navigation, providing more efficient routes by factoring in traffic patterns and unique delays. This shift towards online navigation services has led to a new relationship between individuals and network platforms, where users are part of an evolving dataset and trust the platform's algorithms. The prevalence of AI companions is likely to increase in various sectors, transforming day-to-day reality.

AI-enabled network platforms have provided individuals with unprecedented conveniences and capabilities, but raise questions about the objective function and regulatory parameters of AI. The impact of AI on social norms and institutions, as well as who has access to AI's perception of data, remain essential questions. The limitations of human understanding and access to AI data may be both comforting and unnerving. Network platform operators developed their technology to fulfill human needs and deployed AI to improve their services. Some network platforms have incidentally affected sectors of society beyond their original focus.

AI-driven network platforms have gained social and political influence due to the personal data they collect and the essential services they provide during the pandemic. The role of some platforms in conveying and moderating political information has potentially influenced national governance, without proper preparation. The different spheres of technology and government have different values and objectives, leading to a potential conflict between network platforms and traditional governments. Additionally, AI operates on its own processes, which are different from human decision-making.

AI operates differently than human decision-making and produces outcomes independent of national or corporate cultures. As AI is used to enable network platforms, it can shape social and commercial arrangements on a national and global scale, potentially affecting social and political outcomes. The filtering and presentation of information by social media platforms and their AI can influence the way information is perceived and distributed, potentially reinforcing certain choices and connections. Governmental attempts to address these challenges need to proceed with great care to avoid injecting their own values or purposes.

The choices made by governments regarding the regulation of network platforms and their AI systems reflect value judgments that have significant impacts on society. The intersection of technology and government creates unpredictable and contested results, leading to dilemmas with imperfect solutions. Attempts to regulate network platforms may result in more just societies or more powerful and intrusive governments, and the use of AI in global network platforms may either advance a shared human culture or amplify specific patterns that may undermine intended outcomes. These questions cannot be avoided as our communications rely heavily on AI-assisted networks.

The spread of deliberately malign disinformation is becoming increasingly automated and entrusted to AI, posing a threat to society. Language-generating AI such as GPT3 can create synthetic personalities and spread hate speech at scale, making it difficult for humans to combat the outcome. Content-moderation AI algorithms may be necessary, but there are critical questions regarding who creates and monitors them. As free societies rely on AI-enabled network platforms, novel approaches are needed to police the information environment and balance human judgment with AI automation.

The use of AI to assess and potentially censor information has introduced difficult debates regarding the role of society in defining and suppressing disinformation. Private corporations and democratic governments face a new level of responsibility over shifts in social and cultural developments that were previously not controlled by any single actor. Entrusting the task to AI brings concerns about censorship and the potential for mistakes. The power to train defensive AI and monitor its operations could become a function of importance rivaling the roles traditionally held by government. Small differences in the design of AI could lead to significant societal outcomes.

TikTok's international political and regulatory debates provide a glimpse of the challenges that can arise when using AI to shape communication, particularly when developed in one nation and used by citizens of another. Governments' concerns about the application's collection of user data, censorship, and disinformation led to restrictions on its use and the forced sale of its U.S. operations. As network platforms rely more on AI to provide their services, they will increasingly shape and moderate content.

The use of AI-enabled technology and network platforms poses geopolitical and regulatory challenges for governments and regions, as these platforms operate beyond national borders. It is difficult for countries to create their own advanced national versions of globally influential network platforms due to the rapid pace of technological change, high demand for talent, and substantial costs. This leads to reliance on platforms designed and hosted in other countries, which can create cultural and geopolitical conundrums. The dynamics of positive network effects tend to support only a handful of leading participants in the technology and market for a particular product or service. These challenges suggest more complex geopolitical and regulatory riddles await us in the near future.

Many governments will have an incentive to regulate network platforms that have already been incorporated into fundamental aspects of their society, as they remain dependent on other countries for continued access and key inputs. Governments may manage the training of AI, institute requirements for platform operation, or insist on steps to avoid bias or ethical quandaries. Censorship or removal of public figures' content is possible if they violate content standards. The authority to make and enforce content judgments rests with some companies, reflecting a level of power that few democratic governments have wielded. The emerging geopolitics of network platforms presents a key new challenge that needs to be resolved beyond conventional policy approaches.

The use and behavior of network platforms facilitated by AI are increasingly shaping international strategy, and governments seek to limit their influence. However, the actions of inventors, corporations, and individual users also play a crucial role in shaping the field. Concerns have been expressed about conducting national economic and social life on network platforms facilitated by AI designed in potentially rival countries, leading to new geopolitical configurations. The United States has a leading position in privately operated network platforms due to academic leadership, startup ecosystem, government support, technology standards, and a substantial customer base.

US and Chinese network platforms are viewed as creations and representatives of their respective countries, with the US restricting some foreign platforms and Chinese regulatory approach encouraging competition among domestic technology players. The US is pushing for strategic preeminence and domestic multiplicity, while Chinese network platforms dominate China and nearby regions, with some leading in global markets and having built-in advantages within Chinese diaspora communities. Both countries are shaping international technology standards and restricting export of sensitive technologies.



Chinese network platform operators may not automatically reflect party or state interests and company relationships with the Chinese Communist Party may be complex and varied in practice. 

East and Southeast Asia produce key technologies and locally created network platforms, while also having substantial use of Chinese network platforms and broader engagement with Chinese companies and technology. 

Europe has yet to create homegrown global network platforms or cultivate a domestic digital technology industry, but commands the attention of major network platform operators with its leading companies and universities and tradition of Enlightenment exploration.



Europe faces disadvantages for initial scaling of new network platforms due to serving many languages and national regulatory apparatuses. 

EU focuses regulatory attention on network platform operators' participation and use of AI in its market. 

Europe faces the choice of whether to act as an ally to one side or the other or as a balancer between sides, with varying preferences among traditional EU states and newer Central and Eastern European entrants. 

India has substantial intellectual capital, an innovation-friendly environment, and a large population and economy that could sustain leading network platforms.

India and Russia are two important technological powers with different approaches to network platforms. Indian-designed network platforms have potential to become popular in other markets while Russia's platforms have limited appeal outside its own borders. Both countries are shaping a multidisciplinary contest for economic advantage, digital security, technological primacy, and ethical and social objectives, but the nature of the contest and rules of the game have not been consistently identified. One approach is to treat network platforms and their AI as a matter of domestic regulation to prevent abuses and shirking of responsibilities.

Concepts related to network platform responsibilities are evolving and contested between the US and the EU. One approach is to treat network platforms as an issue of international strategy with concerns about their influence and potential leverage. Countries without homegrown network platforms face the choice of limiting reliance, remaining vulnerable, or counterbalancing potential threats. Some governments may decide the risks of allowing foreign network platforms are unacceptable and need to be balanced by introducing rival platforms.

The emergence of AI-enabled network platforms from one society becoming critical economic infrastructure for another society marks a departure from prior eras. Governments may sponsor a domestic rival or limit the reach of foreign technology into their economies, which may hinder the technology's spread or viability. Prohibiting the use of foreign network platforms identified as threats may create tension with user expectations and raise questions about government regulation.

Network platform operators may need to decide if they will become conglomerates of national and/or regional companies or pursue their values as global companies. Western and Chinese assessments of each other's digital products have grown, and major network platforms may be seen as an expression of American or Chinese culture. Governmental actions are sorting companies into distinctive user camps, which could facilitate regionalization and the development of distinct technology standards. This may lead to communication and exchange becoming increasingly difficult between parallel and entirely distinct lines.

AI-enabled network platforms present complex challenges for individuals, companies, regulators, and national governments. Discussions between these sectors about core concerns and approaches are urgently needed before AI is deployed as part of large-scale network platforms. The human mind is no longer the sole navigator of reality, as AI-enabled network platforms aid it and may eventually displace it. New concepts of understanding and limitations between regions, governments, and network platform operators must be defined.

The advent of AI-enabled network platforms is raising strategic, technological, and ethical dilemmas that require interdisciplinary and global consideration. Strategists should learn from past eras and recognize that prevailing requires a sustainable definition of success. Network platform operators will face challenges in defining national or service ethics and interacting with other sectors of society. Security has always been a minimum objective of organized society, and AI raises new security concerns that require global cooperation.

Throughout history, societies have sought technological advances for surveillance, readiness, influence, and force to achieve security. Innovations such as metallurgy, firearms, and transportation have played a role in warfare. As power has increased, nations have assessed each other's capacity and strategies to maintain a balance of power. In the past century, the calibration of means to ends has become imbalanced due to technological advancements.

Technological advances have grown more destructive while strategies for using them to achieve aims have become more elusive. World War I was a turning point as major powers harnessed technology to construct modern militaries, resulting in a catastrophic war that destroyed a generation and had no relation to the original war aims. The use of advanced military technology, hair-trigger mobilization plans, and diplomatic inflexibility produced a vicious circle that made global war possible and unavoidable.

During the Cold War, the major powers built technologically advanced militaries and alliance systems, but the link between capabilities and objectives remained broken. The dominant weapons technology of the era, nuclear weapons, was never used due to its vast destructiveness being out of proportion to achievable objectives. Today, major powers and other states have augmented their arsenals with cyber capabilities, creating strategies without acknowledged doctrines, and operating at the ambiguous border of disinformation, intelligence collection, sabotage, and traditional conflict.

AI technology holds the potential to augment conventional, nuclear, and cyber capabilities in ways that make security relationships among rivals more challenging to predict and maintain. Defensive functions of AI may soon prove indispensable, but a race for strategic AI advantage is already taking place, particularly between the United States and China. The solution to these complexities is neither to despair nor disarm, but rather to understand and manage the risks of AI technology.

The US and its allies should not stop progress on advanced capabilities, but instead shape and define AI-related strategic doctrines to maintain balance of power and promote democratic accountability. AI rivals should explore setting limits on development and use of destabilizing AI capabilities. Efforts towards AI arms control are not at odds with national security. The use of nuclear weapons in war has broken the link between new weapons and their integration into military arsenals.

During the nuclear age, major powers engaged in debates about the strategic and moral implications of nuclear weapons, including questions about their relation to traditional elements of strategy, the possibility of their calibrated use, and reconciling their use with political objectives short of total war. Despite possessing nuclear weapons, the US did not develop a strategic doctrine or moral principle that would justify their use in an actual conflict following World War II. During the Cold War, the primary objective of nuclear strategy became deterrence to prevent an adversary from taking action through a declared willingness to deploy nuclear weapons.

Nuclear deterrence is a psychological strategy that aims to persuade opponents not to act by means of a threatened counteraction. It relies on a state's physical capacities and its opponent's ability to shape its state of mind. Seeming weakness can have the same consequences as an actual deficiency, and a bluff taken seriously can prove a more useful deterrent than a bona fide threat that is ignored. Nuclear deterrence became a basic concept of international order during the Cold War, with the US using its nuclear arsenal to deter conventional attacks and extend a nuclear umbrella over allied countries. The principal purpose of both superpowers' nuclear weapons increasingly became deterring the use of those weapons by the other side. Survivable nuclear capabilities were relied upon to deter nuclear war itself, and it achieved that objective with respect to conflict among the superpowers. The possession of nuclear arsenals did not deter initiating a conflict or using its own nuclear weapons in one.

The possession of nuclear weapons did not stop nonnuclear states from challenging superpowers or Central and Eastern Europeans from demanding autonomy from Moscow. American policy makers refrained from using nuclear weapons during the Korean War, even when facing defeat at the hands of nonnuclear opponents. The doctrine of massive retaliation, designed to turn any conflict into Armageddon, proved psychologically and diplomatically untenable. Proposals for using tactical nuclear weapons in limited nuclear war foundered on concerns regarding escalation and limits. Nuclear strategy remained focused on deterrence and ensuring the credibility of threats. The US distributed its weapons geographically and constructed a triad of launch capabilities to ensure a devastating response even after a surprise first strike by an adversary.

During the Cold War, the Soviets explored the use of a system that would automatically detect and respond to an incoming nuclear attack, while strategists in government and academia pursued defensive systems to extend decision-making time during a nuclear standoff. However, the pursuit of defensive systems led to an increased demand for offensive weapons, and the threat of nuclear war led to the development of the doctrine of mutual assured destruction (MAD). As a result, nuclear weapons were primarily used for signaling and increasing readiness, with the understanding that their use could lead to global catastrophe. Arms control became a major concern.

Arms control and nonproliferation aimed to prevent nuclear war through the limitation or abolition of weapons, and the prevention of their spread to new nations. These strategies were pursued through treaties and regulatory mechanisms, but have not been fully successful. The arms control era holds lessons for the new arenas of cyber and AI weapons. The US and Soviet Union engaged in arms control dialogue after the Cuban Missile Crisis, eventually limiting their offensive and defensive capabilities through treaties such as the Strategic Arms Limitation agreement and the Anti-Ballistic Missile Treaty.

The Reduction Treaty of 1991 placed limits on offensive weapons to preserve the superpowers' capacity to destroy and moderate arms races. The United States and Russia sought to address the fear of sudden nuclear attacks by educating each other about their strategic capabilities and agreeing on basic limits and verification mechanisms. They also aimed to discourage further proliferation of nuclear weapons through a multicommitment, multimechanism regime that prohibited all but the original nuclear states from acquiring or possessing nuclear weapons. The shared sentiment about nuclear weapons recognized the irreversible decisions and unique risks involved in a nuclear war between major powers. The persistent riddles for policy makers were how to define superiority and limit inferiority in an era where both superpowers had sufficient weaponry to destroy the world many times over.

Countries maintain modest nuclear arsenals to deter attacks, not achieve victory. Nuclear non-use must be secured by adjusting deployments and capabilities of weapons. Cyber conflict and AI have magnified vulnerabilities and transformed conventional, nuclear, and cyber weapons strategy. Maintaining equilibrium in a system based on military power requires consensus regarding constituent elements of power, congruent assessments, and an actual balance. The emergence of new technology has compounded the dilemmas of nuclear weapons.

The use of cyber weapons has transformed the calculation of relative power between nations, creating a new realm of abstraction where their utility derives from their ambiguity and opacity. Unlike conventional and nuclear weapons, cyber weapons exploit undisclosed flaws in software and their intrusions may be masked, making it difficult to determine who is attacking. This creates a higher risk of conflict through miscalculation, particularly when nations have fundamentally different calculations of power.

Cyber weapons, unlike conventional and nuclear weapons, can affect computing and communication systems broadly and be coopted for unintended purposes, making cyber arms control difficult. The ambiguity surrounding cyber terms and concepts further complicates the issue, with various activities referred to as cyber war, cyberattacks, or even an act of war. Intrusions for information gathering may be analogous to traditional intelligence gathering, but other attacks, such as election interference on social media, are new forms of cyber threats. The Stuxnet disruption of Iranian nuclear control computers, a form of industrial sabotage, has not been formally acknowledged by any government.

The digital age has created new forms of cyber conflict, including digitized propaganda, disinformation, and political meddling, which can have a larger scope and impact than previous eras. Cyber actions can also inflict physical impacts similar to traditional hostilities, causing uncertainty over their nature, scope, and attribution. Advanced economies' increasing dependence on digital systems has made them more vulnerable to cyber manipulation and attacks, while the low cost and deniability of cyber operations have encouraged some states to use semiautonomous actors to perform cyber functions.

The cyber domain's speed and ambiguity favor offense, and the unpredictability of various actors may tempt policymakers into preemptive action. Cyber deterrence depends on the defender's aims and how success is measured, as effective attacks occur below the threshold of traditional armed conflict. Strategy and doctrine are evolving uncertainly, requiring close collaboration between government and industry and discussions among major powers. The development and deployment of AI that facilitates strategic action across domains are increasing.

The use of AI in military systems and processes has the potential to revolutionize security policy. AI partnerships with military may lead to surprising insights and may reinforce or negate traditional strategies and tactics. AIs with control over cyber or physical weapons may conduct functions that humans find difficult. However, AI's capacity for autonomy generates incalculability as their logic may be inscrutable and may proceed faster than human thought. The entry of AI into the realm of war introduces new dimensions of uncertainty and contingency, making it difficult to develop offensive or defensive strategies.

The use of AI in weapons systems introduces new dimensions of uncertainty and unpredictability, as their perception and conclusions drawn from phenomena may be difficult to understand. AI may also intensify conflicts and make them more unpredictable, even as it expands the capabilities of existing weapons. Governments should assess the impact of AI on war and explore ways to render it more humane and precise. AI will change actors' strategic and tactical options, enabling conventional weapons to be targeted more precisely.

AI cyber weapons can learn to penetrate defenses without requiring humans to discover software flaws that can be exploited. AI can also be used defensively, but the attacker can choose the target giving the party on offense an advantage. The incorporation of AI technology in combat may change tactics, strategy, or willingness to resort to larger weapons. Generative AI can create false but plausible information, posing unsettling vulnerabilities for free societies. AI could be used to determine the most effective ways of delivering synthetic content to people, tailoring it to their biases and expectations. AI-assisted weapons are being prepared by US rivals, and some are reportedly already being used. There is no widely shared proscription or clear concept of deterrence for AI-assisted weapons.

As transformative AI capabilities evolve and spread, major nations will strive to achieve a superior position, leading to the proliferation of AI technology. AIs fundamentals and key innovations will be public, making controls and regulations imperfect. Efforts to conceptualize a cyber balance of power and AI deterrence are in their infancy. The most revolutionary effect of AI may occur at the point where AI and human intelligence encounter each other. Planning for battle may become more unpredictable as AI technology develops.

The use of AI in military operations involves relying on an intelligence with unfamiliar methods and tactics, which introduces unknown risks. Human operators must be involved to ensure moral agency and accountability. The deeper challenge is that AI may operate in realms inaccessible to human reason, leading to opaque processes and potential delegation of critical decisions to machines. Societies need to initiate a dialogue about the strategic, doctrinal, and moral implications of these evolutions, and an international attempt to limit the risks is imperative.

The strategic use of cyber and AI capabilities extends beyond historic battlefields to anywhere connected to a digital network, creating a system of stunning complexity, reach, and vulnerability. Pursuing mutual understanding and restraint is critical to avoid potential escalation. However, the dynamic nature of AI makes it difficult to establish mutual restraint and verification systems. The range of activities an AI is capable of may need to be adjusted to retain human control and avoid unexpected outcomes.

As AI and cyber capabilities become more widespread, the challenge of defining and limiting them will increase. These technologies can be used by smaller nations to wield outsize influence, and there is a risk that they could fall into the hands of terrorists and rogue actors. AI algorithms will be delegated tasks, including defensive functions, as the attack surface of a highly networked society is too vast to defend manually. Fail-safes should be invested in to insulate against rogue cyber AI disrupting whole sectors. The most significant defensive capabilities will likely be beyond the reach of all but a few nations. The key issue in the domain of lethal autonomous weapons systems is human oversight and the capability of timely human intervention.

It is crucial to ensure appropriate human oversight and mutual restraint in the development and use of lethal autonomous weapons systems, especially in the context of AI increasing the risk of preemption and unintended escalation. Mutual agreement, verification, and enforceable limits should be explored by governments to mitigate these risks. The challenges introduced by AI to strategy should be acknowledged, and the history of nuclear arms negotiations highlights the potential for mutual understanding despite limited trust.



Traditional separation of military and civilian domains was facilitated by technological differentiation, concentrated control, and magnitude of effect. 

Many technologies have been dual-use or possess destructive potential, but none have been both dual-use, easily spread, and potentially substantially destructive until AI. 

AI is emphatically dual-use, spreads easily, and has substantial destructive potential, which creates novel strategic challenges due to the broad range of stakeholders. 

AI-enabled weapons may allow adversaries to launch digital assaults with exceptional speed, dramatically accelerating the human capacity to exploit.



Digital vulnerabilities can leave states with no time to evaluate incoming attacks, necessitating immediate response or risk disablement. 

States may construct AI-enabled systems to scan for and counterattack attacks, potentially triggering an escalatory pattern. 

In the financial world, AI algorithms can exceed human profits but occasionally grossly miscalculate, potentially catastrophic in the strategic domain. 

Incorporating new capabilities into a defined concept of strategy and international equilibrium is complicated by the fact that technological expertise is no longer concentrated exclusively in government.

The development and widespread acquisition of AI pose a complex strategic challenge. The challenge of managing AI is more difficult than managing nuclear weapons due to its dynamic and hard-to-track nature. The achievement of mutual strategic restraint or even a common definition of restraint is more challenging. Mutual education between industry, academia, and government can help bridge the gap and ensure that key principles of AI's strategic implications are understood.

A strategy of responsible use and restraining principles for AI-enabled weapons is essential for a responsible pattern of international relations. Restraining principles should be considered simultaneously with armament, defensive technologies, and arms control. Additional restraints on AI's learning and targeting capabilities must be studied. The US distinguishes between AI-enabled and AI weapons and aspires to restrict use to the former. Defining the nature and manner of restraint on AI-enabled weapons and ensuring mutual restraint is critical.

As AI weapons technology advances, nations must make urgent decisions about what is compatible with human dignity and moral agency. The dilemma is that keeping up with research and development is essential for national survival, but the proliferation of the technology has so far thwarted attempts at negotiated restraint. Each major technologically advanced country needs to convene a body to consider the defense and security aspects of AI and coordinate research on how to prevent unwanted escalation or crisis. The primary AI powers, the US and China, may need to seek consensus to avoid entering into a technologically advanced war with each other.

To avoid a crisis between the US and China in the AI age, a high-ranking subset of officials in each government could be entrusted to monitor and report directly to its president on incipient dangers and how to avoid them. The paradox of the international system is that every power is driven to act to maximize its own security, yet to avoid a constant series of crises, each must accept some sense of responsibility for the maintenance of general peace. In the AI age, strategic logic should be adapted to prevent catastrophic automatic actions and defend against the ease of AI dissemination. The responsibility for avoiding catastrophe may soon spread to many more actors.



 There are six primary tasks in controlling arsenals in the current era, which include conventional, nuclear, cyber, and AI capabilities. 

 Leaders of rival and adversarial nations must regularly speak to each other about the forms of war they do not wish to fight and organize around common interests and values. 

 The challenges of nuclear strategy must be given new attention and recognized as a unique and grave endeavor, with nuclear-armed countries working together to prevent catastrophe. 

 Leading cyber and AI powers should define their doctrines and limits and identify points of correspondence between their doctrines and those of rival powers. 

 Nuclear-weapons states should conduct internal reviews of their command-and-control and early warning systems to strengthen protections against cyber threats and unauthorized or accidental use of weapons. 

 These reviews should include options to reduce the risk of nuclear war and increase transparency in decision-making processes.



 Countries should preclude cyberattacks on nuclear command-and-control or early warning assets and create accepted methods of maximizing decision time during periods of heightened tension. 

 The major AI powers should consider how to limit the proliferation of military AI, such as by undertaking a systemic nonproliferation effort backed by diplomacy and the threat of force. 

 A discussion of cyber and AI weapons among major powers is necessary to manage instability, build mutual security, and ensure strategic equilibrium. 

 In a crisis, human beings must bear final responsibility for whether advanced weapons are deployed, and a mechanism should be agreed upon to ensure decisions are made at a pace conducive to human thought and deliberation.

The article emphasizes the importance of establishing mutual restraint on the development of destructive AI weapons and the need for an ethic of human preservation in the pursuit of national advantage. It also raises the question of how AI will affect human identity and dignity, and how we will reconcile AI with human autonomy. The article reflects on the significance of human achievement and distinctiveness, as well as the changing role of heroes in the modern age.

The article discusses how AI's ability to perform tasks previously done by humans challenges the definition of being human and will change human roles, aspirations, and principles. The rise of AI adds a third way of knowing the world, which will test and transform core assumptions about our place in the world. With AI's ability to predict and simulate reality, the role of human reason will change, leading to a shift in our individual and societal purposes. The article also highlights how AI may augment or sideline human decision-making processes in various areas.

The text discusses how AI is changing the way we interact with the world and ourselves, challenging our self-perception as humans accustomed to agency and intelligence. AI makes predictions, decisions, and generates human-like text, with comparable or superior results to those previously produced only by humans. As AI capabilities increase, it challenges our belief that tasks such as sentence completion are distinct from writing. AI has the potential to become an effective partner for people, leading to new perceptions of the uniqueness and relative value of human capabilities.

The text discusses the need for humans to adjust to a world where AI is a partner, and the significant shift in human experience that it portends. Societies have two options: to react and adapt piecemeal or to engage in a dialogue aimed at defining AI's role and, in so doing, defining ours. The challenge is to understand the transformations AI brings to human experience, the challenges it presents to human identity, and which aspects require regulation or counterbalancing by other human commitments. Ultimately, charting a human future turns on defining a human role in an AI age.



 AI breakthroughs in various fields can be fulfilling for both technically knowledgeable individuals and consumers of AI-managed processes. 

 Embedding AI in consumer products can distribute its benefits widely, but encounters with AI in non-user-centric contexts can be disconcerting or disempowering. 

 AI can be advantageous for managers in decision making, resource distribution, and even creativity. Advances in AI technology can enhance agency and choice for entrepreneurs, administrators, and developers. 

 While optimizing resource distribution and decision making is good for society, for individuals, meaning often comes from autonomy and the ability to explain outcomes based on actions and principles.



 Explanations grounded in human experience are necessary to maintain a sense of autonomy and meaning, but algorithms lack this capability, which may diminish people's ability to understand the world. 

 AI's transformation of work may jeopardize people's identity, fulfillment, and financial security, particularly those in blue-collar, middle-management, and professional jobs involving data interpretation or document drafting. 

 Dislocation caused by AI-driven changes may create new efficiencies and jobs, but it may also leave some feeling obsolete. 

 Previous technological revolutions have also displaced or altered work, prompting changes and unrest, but societies ultimately absorbed the changes for their overall benefit.

The short-term impact of AI will revolutionize certain economic segments, professions, and identities, displacing people and creating a need for alternative sources of income and fulfillment. AI may challenge our sense of agency and responsibility in decision-making, leading to tensions between reasoned explanations and opaque decision-making, individuals and large systems, and people with technical knowledge and authority and people without. The pervasiveness and scale of AI may lead some to reject it, disconnecting from social media or other AI technologies.

As AI becomes more prevalent, some may reject its use and disconnect from the digitized world, but this may prove increasingly difficult. Advances in machine learning are changing the paradigm of scientific discovery, where models are derived from experimental results rather than theoretical understanding, challenging traditional views of human-driven expertise and intuition in science. The development of AI models requires a deep understanding of the problem and the knowledge of which data will be useful for training the model to solve it.

Machine learning is helping scientists across various fields to make new discoveries and develop theoretical models. A prime example of this is the AlphaFold, which uses reinforcement learning to create new protein models, allowing scientists to understand the protein's three-dimensional structure, critical for its biological or chemical outcomes. The partnership between AI and humans is enabling new discoveries that humans are working to understand and explain.

AlphaFold, a program that uses reinforcement learning, has more than doubled the accuracy of protein folding from around 40 to around 85 percent, enabling biologists and chemists to explore new questions about battling pathogens. Advances like AlphaFold are transcending previous limits in measurement and prediction, which are changing how scientists approach what they can learn to cure diseases, protect the environment, and solve other essential challenges. The education and learning of children may be altered in the presence of AI, with AI assistants being able to teach children virtually any language or train them in any subject, serving as playmates or monitors.

As AI-provided and tailored education is introduced, children's dependence on digital assistants may increase and their dependence on human relationships may decrease. This may affect their perception of the world, socialization, imagination, and the nature of play. The impact of digital assistants on children's experiences and development may be an unexpected and uncertain experiment.

As AI companionship for children becomes more common, parents may limit or sanction their children's exposure to AI. Digitization and the constant stream of media can diminish the space for deep thought and contemplation, and AI intermediaries are increasingly shaping our informational domain. AI is being integrated into the process of learning in various domains, including finance and law.

The use of AI intermediaries to navigate and analyze vast bodies of data can both enhance and distort human knowledge. AI can exploit human passions and biases more effectively than traditional propaganda, and market competition may prioritize information that users find most compelling, distorting reality. As a result, some people may seek transparent information filters or rely on traditional human intermediaries for information. However, the majority's acceptance of AI intermediation may impact the future of human knowledge.

The introduction of AI into information and entertainment may limit traditional forms of personal inquiry, and society may lose a common understanding of its history and culture. The use of AI in creative fields raises questions about the unique human engagement with reality and lived experience. The impact of AI on human reason and identity may shift the emphasis from reason to human dignity and autonomy. The Enlightenment era's emphasis on defining human reason may need to be re-evaluated in the age of AI.

The disorientations of the AI age are difficult to mitigate and limiting AI's use may prove challenging due to competitive dynamics. Society-wide or international limitations on AI may be necessary. AI may take a leading role in exploring and managing both physical and digital worlds, prompting humans to retreat into individual, filtered, customized worlds and raising questions about free societies and free will. In other arenas, AI and humans will become equal partners, requiring the development of social structures to understand and interact fruitfully with AI. Societies need to build the infrastructure to engage with AI and exercise its potential.

The deployment of AI will compel adaptation in most aspects of political and social life. The balance between AI and human interaction needs to be established in each major new deployment of AI. Societies and institutions need to adapt to the changes brought by AI and ensure human oversight and participation in core governmental decisions. Deciders in significant issues must be qualified, non-anonymous humans who can offer reasons for their choices. Democracy must retain human qualities, and order without legitimacy is mere force.

The protection of human speech from AI distortion is crucial for meaningful democratic deliberation and elections. Free speech needs to be continued for humans but not extended to AI to prevent the spread of misinformation and disinformation. It is important to develop understandable distinctions between automated AI speech and genuine human speech, and regulation of AI intermediation is crucial to prevent the promotion of deliberately created falsehoods. Each society must determine permissible and impermissible uses of AI, and access to powerful AI like AGI must be strictly guarded to prevent misuse.

Limits on AI access will vary by society and some limits may require international collaboration, such as restricting the use of AI in the production of biological weapons. The EU has outlined plans to regulate AI to balance European values and economic development, including risk assessments and limits or bans on government use of certain technologies. Efforts to examine the relationships between existing processes and structures and the rise of AI are underway in academia and government in the United States. Societies that adapt their institutions in advance through analysis will advance, while those that forgo analysis may fall behind.

The development of AI will require the establishment of new institutions to maximize its benefits, and AI may reveal realities and patterns beyond human imagination or language. This may lead to a redefinition of human capabilities and the reality we thought we were exploring, transforming basic assumptions and societal arrangements.

The AI revolution is imminent and will require new concepts to navigate its transformations in every aspect of life. The changes brought by advances in printing in medieval Europe provide a historical comparison. Gutenberg's printing press revolutionized knowledge dissemination and changed every sphere of life, making knowledge accessible to more people. Similarly, the AI revolution will require new ways to adapt and maintain a human relationship with reality.

Before the printed book, knowledge was primarily accessed through community traditions, faith, and guilds. Printed books changed the relationship between individuals and knowledge, allowing for quick spread of new information and ideas, leading to significant societal changes. Currently, technology and artificial intelligence are transforming knowledge and individual thought, despite lacking human qualities.

Artificial intelligence has the potential to produce results that surpass human reasoning and reveal new aspects of reality, leading to scientific and economic advances that transform the world. However, the impact of AI on discourse and human capacity for skeptical inquiry is uncertain, and it may channel societies into separate and contradictory branches of reality. The existence of AI challenges fundamental assumptions about human understanding of reality and our relationship to it.

AI's achievements challenge established concepts and provide new insights, sometimes surpassing human capabilities. AI expands and organizes the digital world, but also hastens dynamics that erode human reasoning, such as social media and online searching. Its impact on reality is a new and sophisticated entity, providing access to new horizons.

As deep reading and analysis decline, AI's ability to affect human thought and its role in reviewing and making sense of information expands. AI can provide objective facts but may also reshape information to conform to biases, potentially narrowing access to objective truth. In the age of AI, human reason will be both augmented and diminished. As AI becomes more prevalent, there may be a reenchantment of the world, with some deferring to AIs as quasi-divine judgments.

The article discusses how AI is perceived as godlike intelligence, and how individuals may opt out of using AI to preserve their own reasoning abilities. However, forgoing AI at a societal level is not feasible and requires an ethical approach involving computer scientists, business leaders, military strategists, political leaders, philosophers, and theologians. Humanity has three options when it comes to AI: confining it, partnering with it, or deferring to it, and each application requires charting a course that reflects both philosophical and practical dimensions.

The article explores the evolving relationship between humans and AI, including the appropriate use of deference, partnership, and limitations. AI will transform our approach to knowledge and truth, elevating a concept of knowledge that is the result of partnership between humans and machines. AI already transcends human perception, and the question remains whether humans and AI are approaching the same reality from different standpoints, with complementary strengths, or perceiving two different realities. The concept of artificial general intelligence raises questions about the limits of human and AI cognition.

The quest for knowledge may require AI to acquire certain knowledge that humans cannot conceptualize. As AI develops towards AGI, questions arise regarding who controls it, who grants access, and whether democracy is possible in a world with few organizations operating it. AI has the potential to revolutionize human affairs but also requires regulation and monitoring to prevent it from diverging from our expectations and intentions. The decision to confine, partner with, or defer to AI will not be solely made by humans.

Competition to deploy AI may lead to a race to the bottom without adequate assessment of risks. An AI ethic is necessary to guide decisions for shaping the future. Designers and deployers of AI should address concerns about its opacity and explain what AI is doing and how it knows. AI's emergent qualities generate ambiguity in generating unforeseen results that may carry humanity to places its creators did not anticipate.

The deployment of AI without careful consideration can lead to grave consequences, including unpredictable actions. AI objectives and authorizations need to be designed with care, especially in fields where decisions could be lethal. AI should not be treated as automatic and must be overseen by humans. However, many creators of AI may not consider the broader implications of their technology. The AI age needs reasoned discussion and negotiation to establish limits on practical actions. AI is distinct from regulated products, services, technologies, and entities, and requires its own philosophical perspective to understand its broader implications.

The governance of AI requires a fully defined conceptual and legal framework, including an ethic that reflects the challenges posed by AI's nature. The introduction of AI complicates existing principles of justice applied to humans. Responsibility for AI actions and the ability to explain its decisions are important issues to consider. Determining when and in what contexts AI should be subject to internationally negotiated restrictions is essential, but difficult to achieve due to the challenge of designing effective verification regimes for an ethereal, opaque, and easily distributed technology.

The development of AI raises profound ethical questions and requires the involvement of various experts and stakeholders, including technologists, ethicists, corporations, and governments. As much of social and political life takes place on network platforms enabled by AI, it is important to determine the technology's role, regulation, and accountability. The impact of AI on social media and democracy raises concerns about the unilateral promotion or removal of content, the distortion of information, and the loss of agency in navigating curated domains. Principles must be developed to address AIs forms of perception and decision making.

The distribution of harmful and disinformation on social media highlights the need for limits and standards, but the definition of harmful information should not be left solely to corporations or government agencies. AI's role in moderating content must be clear and subject to external review and some form of human appeal. Societies will vary in their emphasis on free speech and their relationship with AI, which is porous and shaped by human influence.

The article discusses the potential implications of AI for international relations, including questions about regulation, state sovereignty, and the role of humans in decision-making. It highlights the importance of shaping AI in a way that aligns with human values and acknowledges the limitations of both AI and human leadership.

The article discusses the need for accommodating AI's superhuman capabilities into imperfect human contexts, and the potential for destabilization in the security realm if weaponized AI is not regulated. It also raises questions about the availability of AI-enabled weapons and the potential for terrorists to use AI to conduct attacks and falsely attribute them to other actors. The article highlights the need for a framework to regulate AI and cyber weapons, and the challenges of adapting diplomacy to the diffusion of AI in governments' defense functions.

The rise of AI technology will break down barriers of geography and language, but also create challenges in communication and security, particularly in the development of AI-enabled cyber weapons. These weapons are difficult to control and attribute, and the unpredictability of AI makes arms control difficult. The development of a new framework for arms control in the age of AI is imperative.

As AI and other emerging technologies advance, there is a need for a philosophical framework to guide their development and use. The potential military uses of AI are broader than those of nuclear arms, and the lines between offense and defense are unclear. The great powers must engage in dialogue to avert catastrophe and survive. While AI has the potential for profound benefits, it can also compound the complexity of information consumption and identification of truth, requiring careful consideration of its use.

The United States needs to make AI a national priority and establish a commission led by respected figures to ensure the country remains competitive in AI and raise awareness of its cultural implications. The group should engage with existing national and subnational groups and align technology, strategy, and philosophy. They must also answer questions about how to integrate AI into traditional societal norms and achieve a superior society. Finally, there is a meta question of whether humans assisted by AIs can meet the need for philosophy and whether humans can make peace with machines and change as a result.

Humanity has long grappled with questions beyond the capacity of human reason, and the advent of AI may yield progress on these questions. However, it will also produce new questions, and developing an ethical framework for the partnership between human and artificial intelligence will require commitment and insight from many sectors of society. The book emphasizes the need to define this partnership and the reality that will result, and it acknowledges the contributions of colleagues and friends in facilitating this discussion.

The text acknowledges and expresses gratitude to the individuals who contributed to the creation of a manuscript on the topic of artificial intelligence. These contributors include the authors, editors, and people who provided feedback and support throughout the project. The text also includes notes on relevant statistics and events related to artificial intelligence.

The text includes a list of references to sources related to various aspects of artificial intelligence, including its applications in fields like chess, drug discovery, and data center management, as well as its impact on military technology and philosophical discourse. The text also includes a quote from Edward Gibbon's "The Decline and Fall of the Roman Empire" and notes that inquiries into national interests and statecraft have a long history in many civilizations, including China.

The text discusses the different cultural and philosophical perspectives on reality and knowledge, comparing the Western Faustian society's impulse towards unlimited knowledge and expansion to Eastern traditions' recognition of subjective and relative experiences of reality. The author references various philosophers, including Spengler, Cassirer, Spinoza, and Kant, and notes Kant's view on the limitations of human theoretical reason and the importance of belief in the divine. The text also briefly mentions Kant's ideas on perpetual peace and Michael Guillen's book on five equations that changed the world.

The text discusses the relationship between power and technology, specifically in the context of mathematics, artificial intelligence, and digital platforms. The author references various philosophers and scientists, including Heisenberg, Wittgenstein, Turing, and Ferguson, and notes the potential dangers and biases that can arise in technology, such as racist algorithms and adversarial attacks. The text also briefly touches on the history of centralized power and networks and defines network platforms as online services with positive network effects.

The text discusses various aspects of the impact of artificial intelligence, including its effects on the economy, search engines, and social media. It also examines positive network effects and their relationship to economies of scale, as well as the potential risks posed by advanced neural language models. The text suggests that AI has significant potential to transform various aspects of society, including military strategy, and highlights the importance of understanding its implications for the future.

The text discusses various aspects of global power and security, particularly in relation to nuclear weapons and cybersecurity threats. It references historical and current events, including the Cold War arms race, the US nuclear triad, and Russian cyberattacks such as the NotPetya malware. The text highlights the importance of understanding and addressing these risks in order to maintain global security.

The text contains references to various sources discussing the intersection of cybersecurity and artificial intelligence (AI) in the context of national security and military operations. The sources discuss topics such as defending against cyber threats, AI-controlled military systems, and the use of learning algorithms in autonomous weapons systems. The references also highlight the importance of critical and emerging technologies in national security, as well as the role of AI in future high-tech warfare.

The text contains references to various sources discussing the use of artificial intelligence (AI) in economic and social development, as well as the ethical principles and policy frameworks surrounding the use of autonomous weapon systems in national defense. The sources include government directives, reports, and speeches from international leaders. The references highlight the need for ethical considerations and policy guidance in the development and deployment of AI technologies in various contexts, including the military.

The text contains a list of various sources and references without any apparent connection or coherent topic.

